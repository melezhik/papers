# Fast monitoring scripts development

# Once upon a Friday

Are you a smart web developer using Mojolicious, Dancer2, Kelp, Limper or just CGI ?
Sure, Yes you are! ;-) You have just finished yet another web application ready to get deployed
and awaited with impatience by your customers. All your 't/' are fine, you for sure use Plack::Test
or familiar tool to tests your application not only in internal but external way. Everything is going to be
fine, even though it's Friday today and is not probably good time to make a release, but you so
anxious to see a results and get users input, so you are coming to John - devops guy and pointing him a git URL where your source code lives in so he could start the deploy procedure ...


... But, yes, there are some "hurdles" always. John kindly asking you to provides some monitoring
capabilities for your freshly baked application, so he could make it sure it won't break
on weekend silently not to alarm anybody ...


# Ah, yeah you talk about monitoring ... ?

"Ah, monitoring John, yes, sure ..." - thoughts have passed in your mind.

"Well John, you could try a curl or check_http or something else and write your own bash script to get this done.
It's easy for sure, you only have to take care about cookies get sent back upon successful authentication,
you know curl "knows" cookies, you know cookie as well? Also there is a database endpoint you need to call periodically 
to ensure application does not lost DB connection.

That's it!

And ... Yeah, you know this a route for this called GET /database-info ... Just use it"

Saying all these phrases you are looking at John's face and have noticed as him is getting unhappy, a moment after you start to  realize why.

" Ah, Alex ( this is your name ) -  ... Routes, cookies, authentication ... what your are talking about ?
Sorry, I am pretty swamped by other duties, you know a couple web applications coming from next department
have been waiting to get deployed since yesterday."

"I am really sorry, but can't do what you talk about right now.
What if you come at me on Monday, and we sit together and drop some tests for your application monitoring?
You know I'd be happy to deploy it, but need some tests first ..."

Now it's time _for you_ to be unhappy ...

# SWAT/ Sparrow - Don't be unhappy

[Swat](https://github.com/melezhik/swat) is a DSL for rapid web tests development. Sparrow provides some glue
to push your tests into prodcution.

Let see how we could use both of these tools to make Alex life more happy and letting him
find better colloboration with his collegues.


Alex's application besides that cool and important for customers, exposes some essential endpoints we 
have to talk about a little bit:

* POST /login
* GET  /database-status

The first one, obviosly is for letting user sign in and should be considered as most important part of the application. 
Upon success login server returns session cookie and redirect user to profile page with greetings:

     Hello user! This is profile page 


And the second one, is not intended to hit by human - as it name hints - this is for getting some database infomation status
by ... right monitoring script, this endpoint was accidentally told by Alex as `GET  /database-info' 
in his conversatiuon with John.


Okay having this we could drop some tests for two routes, in a minimal time and with minimal efforts:

First of all let's create a directory to hold our tests scenarios:

    $ mkdir app-monitoring
    $ cd app-monitoring


Then let's define  mentioned routes:

    $ mkdir login/
    $ mkdir database-status/

Now, we are almost done. We need to define a content which we expect to get when request the routes.

One for login:

    $ echo '200 OK' > login/post.txt
    $ echo 'Hello user! This is profile page' >> login/post.txt


And one for database-status

    $ echo '200 OK' > database-status/get.txt
    $ echo 'database is running!' >> database-status/get.txt

And, yes , our application send cookies and make http redirect to /profile page upon succesfull login,
so we need to take care about this:

    $ nano login/swat.ini
    curl_params="-d username=$username -d password=$password --cookie-jar ${test_root_dir}/cookie.txt"

And finaly let run our tests manualy to see they works:

    username=alex password=123456 swat ./ 127.0.0.1:3000

    vagrant@Debian-jessie-amd64-netboot:~/projects/papers/blogs-perl-org/app-monitoring$ username=alex password=123456 swat ./ 127.0.0.1:3000
    /home/vagrant/.swat/.cache/18844/prove/database-status/00.GET.t ..
    ok 1 - GET 127.0.0.1:3000/database-status succeeded
    # response saved to /home/vagrant/.swat/.cache/18844/prove/sL6VpL2brR
    ok 2 - output match '200 OK'
    ok 3 - output match 'database is running!'
    1..3
    ok
    /home/vagrant/.swat/.cache/18844/prove/login/00.POST.t ...........
    ok 1 - POST 127.0.0.1:3000/login succeeded
    # response saved to /home/vagrant/.swat/.cache/18844/prove/CZEawnHwv_
    ok 2 - output match '200 OK'
    ok 3 - output match 'Hello user! This is profile page'
    1..3
    ok
    All tests successful.
    Files=2, Tests=6,  0 wallclock secs ( 0.02 usr  0.00 sys +  0.10 cusr  0.00 csys =  0.12 CPU)
    Result: PASS
    

Hurah! We have just succeeded with monitoring script ready to use, but we deliver it to John?


# Little sparrow to ship your monitoring scripts









 
